{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><span style=\"color:red;\">**IMPORTANT NOTICE**</span></center></h1>\n",
    "\n",
    "Before submitting, **please**, make sure that your notebook runs **without errors** in Python 3.6\n",
    "and **reproduces your solution as intended**, when you **Restart the Kernel and re-run the whole\n",
    "notebook**!\n",
    "<span style=\"color:red;\">You will be severely penalized if you notebook does not run.</span>\n",
    "\n",
    "Whereever applicable your solution will be graded based on the **plots**, generated by\n",
    "**your code** on **TA's** computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> <!--Intentionally left blank-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Assignment -- 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, write your implementation within the designated blocks:\n",
    "```python\n",
    "...\n",
    "### BEGIN Solution\n",
    "\n",
    "# >>> your solution here <<<\n",
    "\n",
    "### END Solution\n",
    "...\n",
    "```\n",
    "\n",
    "Write your theoretical derivations within such blocks:\n",
    "```markdown\n",
    "**BEGIN Solution**\n",
    "\n",
    "<!-- >>> your derivation here <<< -->\n",
    "\n",
    "**END Solution**\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\LaTeX$ in Jupyter\n",
    "Jupyter has constantly improving $\\LaTeX$ support. Below are the basic methods to\n",
    "write **neat, tidy, and well typeset** equations in your notebooks:\n",
    "* to write an **inline** equation use \n",
    "```markdown\n",
    "$ you latex equation here $\n",
    "```\n",
    "* to write an equation, that is **displayed on a separate line** use \n",
    "```markdown\n",
    "$$ you latex equation here $$\n",
    "```\n",
    "* to write a **block of equations** use \n",
    "```markdown\n",
    "\\begin{align}\n",
    "    left-hand-side\n",
    "        &= right-hand-side on line 1\n",
    "        \\\\\n",
    "        &= right-hand-side on line 2\n",
    "        \\\\\n",
    "        &= right-hand-side on the last line\n",
    "\\end{align}\n",
    "```\n",
    "The **ampersand** (`&`) aligns the equations horizontally and the **double backslash**\n",
    "(`\\\\`) creates a new line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> <!--Intentionally left blank-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/> <!--Intentionally left blank-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 (19 pt.): Model selection and sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> <!--Intentionally left blank-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (2 pt.): Information criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that regression model is\n",
    "$$y = \\sum_{i=1}^k \\beta_i x_i + \\varepsilon,$$\n",
    "and $\\varepsilon$ is dictributed as normally: $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$, $\\sigma^2$ is known.\n",
    "\n",
    "Prove that the model with highest Akaike information criterion is the model with smallest Mallow's $C_p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BEGIN Solution**\n",
    "\n",
    "\n",
    "**END Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> <!--Intentionally left blank-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (17 pt.): Sensitivity analysis and optimization for rotating disk problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tsk, you are proposed to solve a problem of optimization of a rotating disc. You will use approximation techniques, sensitivity analysis and optimization. For sensitivity analysis you are recommended to use SALib library (https://github.com/SALib/SALib), and scipy for optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Parameters `r1,t1,r2,r3,t3,r4` are input variables that define a geometrical shape of a disk. Parameters `mass,smax,u2` are mass of a disk, maximal radial stress, and contact stress, respectively. **Those are the\n",
    "target variables to predict (yes there are three regression targets).**\n",
    "2. The `problem` Pythonic dict is used for SALib methods and defines bounds for parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following command in the next empty code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "!pip install salib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from SALib.analyze import sobol as sobol_analyzer\n",
    "from SALib.analyze import morris as morris_analyzer\n",
    "\n",
    "from SALib.sample import saltelli as saltelli_sampler\n",
    "from SALib.sample import morris as morris_sampler\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem is defined as a simple Pythonic dict, where you should number of input variables,\n",
    "bounds for each input variable and their names. This will be helpful for sensitivity analysis.\n",
    "Note, that bounds defined here are true for **standardized data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "problem = {\n",
    "    'num_vars': 6,\n",
    "    'names': data.columns.values[:6],\n",
    "    'bounds': np.array([[-1.7321, 1.7321],\n",
    "                        [-1.7321, 1.7321],\n",
    "                        [-1.7321, 1.7321],\n",
    "                        [-1.7321, 1.7321],\n",
    "                        [-1.7321, 1.7321],\n",
    "                        [-1.7321, 1.7321]]),\n",
    "    'groups': None\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> <!--Intentionally left blank-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1 (7 pt.): Surrogate modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual dependency is not given, only a data set of inputs and outputs.\n",
    "Surrogate modelling is an approach that allows to construct approximations of the real dependecy, and use them for optimization and modelling.\n",
    "To perform sensitivity analysis and optimization we are going to use a regression model.\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "* Load the data set from `data/doe_100.csv`.\n",
    "* Build several regression models using different techniques: Gaussian Process Regression, Kernel Ridge regression, SVR.\n",
    "* Perform k-fold cross-validation for each model and choose the best.\n",
    "\n",
    "The most accurate models will be used in **all subsequent excersices**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**NOTE**</span> sklearn has a convenient GP implementation.\n",
    "\n",
    "```python\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import My, Favourite, Kernels, ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### BEGIN Solution\n",
    "\n",
    "# >>> your solution here <<<\n",
    "\n",
    "### END Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> <!--Intentionally left blank-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2 (6 pt.): Sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SALib is a python library for sensitivity analysis.\n",
    "\n",
    "It implements some popular global sensitivity analysis methods: \n",
    "* Morris method - that may be thought of as crude estimation of average absolute value of partial derivative. \n",
    "* Sobol indicies - that show portion of variance in the output that is explained by input.\n",
    "\n",
    "Each method takes **x** and **y** samples as input. But the samples must be properly generated.\n",
    "There are special functions in SALib library to do exactly that.\n",
    "\n",
    "Using the **best model per target** your task is to\n",
    "\n",
    "* calculate Sobol indices:\n",
    "    * Generate **x** and **y** samples using Saltelliâ€™s extension of the Sobol sequence\n",
    "    * Calculate Sobol indices using obtained samples\n",
    "* calculate screening indices\n",
    "    * Generate **x** and **y** samples for Morris method\n",
    "    * Apply Morris method to generated samples to obtain screening indices\n",
    "\n",
    "\n",
    "* Using your judgement and based on the analysis results choose variables have the most influence on the output.\n",
    "\n",
    "**NOTE** Make sure to use the *same sample* for all three targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### BEGIN Solution\n",
    "\n",
    "# >>> your solution here <<<\n",
    "\n",
    "### END Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> <!--Intentionally left blank-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3 (4 pt.): Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final goal is to optimize the **mass** of the rotating disk. It will be done with scipy optimizer via approximation, provided by the surrogate model. We assume that surrogate model is of reasonable quality. The optimization problem for full parameter space is prepared for you.\n",
    "\n",
    "The following optimization problem should be solved:\n",
    "\n",
    "$$\n",
    "{\\rm mass} \\rightarrow \\min_x \\\\\n",
    "\\mbox{subject to} \\quad S_{max}(x) \\le 600 \\\\\n",
    "\\qquad \\qquad U_2(x) \\le 0.3\n",
    "$$\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "* Perform optimization by running the code below\n",
    "* After performing sensitivity analysis you got the most influential features. Reestimate your models on the reduced feature space\n",
    "* Change the optimization problem statement so that it usess only the selected variables\n",
    "* Compare the optimal results for two formulations considered and make a conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimize(lambda x: best_models[0].predict(x.reshape(1, -1)),\n",
    "                  [109.0, 32.0, 123.0, 154.0, 6.0, 198.0],\n",
    "                  bounds=problem['bounds'],\n",
    "                  constraints=[{'type': 'ineq',\n",
    "                                'fun' : lambda x: 600 - best_models[1].predict(x.reshape(1, -1))\n",
    "                               },\n",
    "                               {'type': 'ineq',\n",
    "                                'fun' : lambda x: 0.3 - best_models[2].predict(x.reshape(1, -1))\n",
    "                               }])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### BEGIN Solution\n",
    "\n",
    "# >>> your solution here <<<\n",
    "\n",
    "### END Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> <!--Intentionally left blank-->"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
