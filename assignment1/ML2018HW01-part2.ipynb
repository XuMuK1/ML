{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment -- 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 (13+3 pt.): Free range practical classification\n",
    "\n",
    "In this assignment you are asked to apply different classifiers to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_full, y_full = make_classification(n_samples=2400, n_features=20, n_informative=18,\n",
    "                                     n_redundant=0, n_classes=2, random_state=2319)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are asked to play around with these binary classification models from\n",
    "the third lecture:\n",
    "* logistic regression\n",
    "* $k$-nearest neighbours\n",
    "* Decision Tree\n",
    "\n",
    "and check out different calssification quality measures.\n",
    "\n",
    "You are free to use **sklearn**, **pandas**, **numpy** or any other library to the\n",
    "fullest. Try to avoid writing code, and instead rely on the already implemented and\n",
    "validated solutions.\n",
    "\n",
    "Your goal is to **explore and experiment** with the dataset using these models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make train / test split (2 pts.)\n",
    "\n",
    "This step is just it: split the sample $(X, y)$ into a **train** and **test**\n",
    "sample. The trick is to make the split arbitrarily random, yet **replayable**,\n",
    "i.e. each separate run of your notebook **must yield exactly the same results**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection (7+3 pt.)\n",
    "\n",
    "In this step you are asked to perform hyperparameter selection with $k$-fold cross\n",
    "validation on the **training sample**.\n",
    "\n",
    "Again, make sure that the folds are generated randomly, yet **replayable** as in the previous step.\n",
    "\n",
    "Tutorial on cross validation in [sklearn](http://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html)\n",
    "\n",
    "Basically you need to:\n",
    "1. Select a range of the hyperparameter you are tuning:\n",
    "    * penalty type, regularization coefficient for Logistic Regression;\n",
    "    * Tree depth, number of features per split for Decision Trees;\n",
    "    * the number of neighbours in $k$-NN, etc.\n",
    "2. Pick a metric to evaluate with (Accuracy, precision, recall, $F_1$, or custom etc.)\n",
    "3. Search for the best parameter using cross-validation and save the best model\n",
    "4. rinse and repeat for another model / parameter settings.\n",
    "\n",
    "You get extra points if you tune more than one hyperparameter.\n",
    "To do this you will have to decide either\n",
    "* to test all possible combinations of parameters\n",
    "* or to employ a greedy optimization strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the best models (4 pt.)\n",
    "\n",
    "In this step you are to plot the [ROC curve](http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html) of\n",
    "the best models on the **test sample**. Then using the ROC-AUC (or any\n",
    "**other metric** you like) to decide which model is **the best of\n",
    "the best**.\n",
    "\n",
    "Try to be creative and not just copy the provided reference tutorials.\n",
    "Don't worry if the final overall performance metric is not that high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
